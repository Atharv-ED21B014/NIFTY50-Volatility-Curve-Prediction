{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1J0MfH87XJQmWPVWVNxPiv9zS4OoU1xCs","timestamp":1749329435639},{"file_id":"1HypFb6gG-ZZkZSQMZGIVW76w27yMWlVY","timestamp":1749325788605},{"file_id":"1o6jhpMKfvD4mKZ6Zen_ftV0r8gn9rqR_","timestamp":1749325334996}],"authorship_tag":"ABX9TyMvH1/7YhTPvQwYKtgIFazq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MOR9RnpvNLNR"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","from google.colab import drive"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n"],"metadata":{"id":"8UeKnaFZGfNv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path='train_data.parquet'"],"metadata":{"id":"jIqGEXx-Ndm_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.read_parquet(file_path,engine='auto')"],"metadata":{"id":"zcUgXC7LOVQi","executionInfo":{"status":"error","timestamp":1749330834212,"user_tz":-330,"elapsed":730,"user":{"displayName":"Atharv Satish Karkar ed21b014","userId":"06868631312639107579"}},"colab":{"base_uri":"https://localhost:8080/","height":287},"outputId":"18ad5b6f-2f75-400c-c7f6-38d8a3fe53f0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'train_data.parquet'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-6ba5db3fcba3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data.parquet'"]}]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"baN7IEkAOXGD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path_test='test_data.parquet'\n","test_df=pd.read_parquet(file_path_test,engine='auto')\n","train_cols = df.columns\n","test_cols = test_df.columns\n","iv_cols = [col for col in df.columns if \"_iv_\" in col]\n","# cols involving iv data\n","test_iv_cols = [col for col in test_df.columns if \"_iv_\" in col]\n","train_call_iv_cols = [col for col in train_cols if \"call_iv_\" in col]\n","train_put_iv_cols = [col for col in train_cols if \"put_iv_\" in col]\n","test_call_iv_cols = [col for col in test_cols if \"call_iv_\" in col]\n","test_put_iv_cols = [col for col in test_cols if \"put_iv_\" in col]\n","# cols involving iv data\n","# Columns in train but not in test, in original train order\n","train_spec_cols = [col for col in train_cols if col not in test_cols]\n","train_spec_call_iv_cols=[col for col in train_spec_cols if \"call_iv_\" in col]\n","train_spec_put_iv_cols=[col for col in train_spec_cols if \"put_iv_\" in col]\n","# Columns in test but not in train, in original test order\n","test_spec_cols = [col for col in test_cols if col not in train_cols]\n","test_spec_call_iv_cols=[col for col in test_spec_cols if \"call_iv_\" in col]\n","test_spec_put_iv_cols=[col for col in test_spec_cols if \"put_iv_\" in col]\n","common_call_iv_cols = [col for col in train_call_iv_cols if col in test_call_iv_cols]\n","common_put_iv_cols = [col for col in train_put_iv_cols if col in test_put_iv_cols]"],"metadata":{"id":"L3EVETfG6Hgl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["common_cols=common_call_iv_cols+common_put_iv_cols"],"metadata":{"id":"dw_KYIqvC7VZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path='/content/drive/MyDrive/NK_Hack/df_ready_export.csv'\n","df_ready_2=pd.read_csv(file_path)\n","df_ready_2.drop(train_spec_cols,inplace=True,errors='ignore')\n","df_ready_2.shape"],"metadata":{"id":"TpjdmRbA7fSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path_test='/content/drive/MyDrive/NK_Hack/df_spline_fill.csv'\n","df_fire_imputed_spline=pd.read_csv(file_path_test)"],"metadata":{"id":"HFbxXOSZ7f2E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()"],"metadata":{"id":"0-5TyibQtchY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LinearRegression, Ridge\n","from sklearn.neural_network import MLPRegressor\n","from xgboost import XGBRegressor\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.datasets import make_regression\n","import numpy as np\n","\n","\n","\n","# Define parameter grids\n","param_grids = {\n","    \"LinearRegression\": {\n","        \"regressor\": [LinearRegression()]\n","    },\n","    \"Ridge\": {\n","        \"regressor\": [Ridge()],\n","        \"regressor__alpha\": [0.01, 0.1, 1.0, 10.0]\n","    },\n","    \"MLP\": {\n","        \"regressor\": [MLPRegressor(max_iter=500)],\n","        \"regressor__hidden_layer_sizes\": [(64,), (128, 64)],\n","        \"regressor__alpha\": [0.0001, 0.001],\n","        \"regressor__learning_rate_init\": [0.001, 0.01]\n","    },\n","    \"XGB\": {\n","        \"regressor\": [XGBRegressor(verbosity=0)],\n","        \"regressor__n_estimators\": [100, 200],\n","        \"regressor__max_depth\": [3, 5],\n","        \"regressor__learning_rate\": [0.05, 0.1]\n","    }\n","}\n","\n","# Now you can use best_model like this:\n","# best_model.fit(X, y)  # Already fit above, but reuse on new data if needed"],"metadata":{"id":"EmAzoY63N2X3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"L8nDX39jrWcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path_test='test_data.parquet'\n","test_df=pd.read_parquet(file_path_test,engine='auto')\n","train_cols = df.columns\n","test_cols = test_df.columns\n","# Columns in train but not in test, in original train order\n","train_spec_cols = [col for col in train_cols if col not in test_cols]\n","\n","# Columns in test but not in train, in original test order\n","test_spec_cols = [col for col in test_cols if col not in train_cols]\n","\n","print(\"Ordered columns in train_data.parquet that are absent in test parquet:\", train_spec_cols)\n","print(\"Ordered columns in test_data.parquet that are absent in train parquet:\", test_spec_cols)\n"],"metadata":{"id":"CvnWUnTCPTih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path='df_ready_export.csv'\n","df_ready_2=pd.read_csv(file_path)\n","df_ready_2.drop(train_spec_cols,inplace=True,errors='ignore')\n","df_ready_2.shape"],"metadata":{"id":"nghuYQ024__l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path_test='df_spline_fill.csv'\n","df_fire_imputed_spline=pd.read_csv(file_path_test)"],"metadata":{"id":"m5VnrrbD5BqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.drop(train_spec_cols,axis=1,inplace=True)"],"metadata":{"id":"ru19IYnKPuxg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"0BXW-P_vQjsu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iv_cols = [col for col in df.columns if \"_iv_\" in col]\n","# cols involving iv data"],"metadata":{"id":"9SWA5-PTXHwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_iv_cols = [col for col in test_df.columns if \"_iv_\" in col]\n","# cols involving iv data"],"metadata":{"id":"-Zau5bVbEaDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot iv_cols from df_1 as histogram\n","\n","df[iv_cols].hist(bins=50, figsize=(20,15))\n","plt.show()"],"metadata":{"id":"trjJBeifJdV1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: cells with _iv_ columns should lie between 0 and 2\n","\n","# Identify columns that contain '_iv_'\n","iv_cols = [col for col in df.columns if \"_iv_\" in col]\n","\n","# Filter the DataFrame to keep only rows where all _iv_ columns are between 0 and 2\n","df_filtered = df[(df[iv_cols] >= 0.05).all(axis=1) & (df[iv_cols] <= 0.7).all(axis=1)]\n","\n","# You can now work with df_filtered which contains the data that satisfies the condition\n","# print the shape of the filtered dataframe to see how many rows remain\n","print(f\"Original shape: {df.shape}\")\n","print(f\"Filtered shape: {df_filtered.shape}\")\n","\n","# Optionally, you can replace the original dataframe with the filtered one\n","# df = df_filtered"],"metadata":{"id":"YpHY16vZFRqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_filtered[iv_cols].hist(bins=50, figsize=(20,15))\n","plt.show()"],"metadata":{"id":"r4PV3ka5FA5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = StandardScaler()"],"metadata":{"id":"-QXS2HuwKs3D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(ds_frame):\n","  drop_worthy=['timestamp']\n","  filtered_df=ds_frame.drop(drop_worthy,axis=1)\n","  cols_to_scale = [col for col in filtered_df.columns if '_iv_' not in col]\n","\n","# Apply StandardScaler to the identified columns\n","  filtered_df[cols_to_scale] = scaler.fit_transform(filtered_df[cols_to_scale])\n","  return filtered_df"],"metadata":{"id":"3Q0Na2wSKJqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_ready=preprocess(df_filtered)\n","df_ready.head()"],"metadata":{"id":"XA1eCfr0KEbM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire=preprocess(test_df)\n","df_fire.head()"],"metadata":{"id":"rtGkL7VaLSXi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error"],"metadata":{"id":"pDPuZNSwvAji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr=LinearRegression()"],"metadata":{"id":"oUdlJKravIbV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire[test_spec_cols]"],"metadata":{"id":"0LuoB2ylLiyO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer,KNNImputer\n","simp_imp=SimpleImputer(missing_values=np.nan, strategy='mean')\n","knn_imputer=KNNImputer(n_neighbors=5)"],"metadata":{"id":"nmBoFVCFOdQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire_copy=df_fire.copy()\n","df_fire_copy.drop('underlying',axis=1,inplace=True)\n","from sklearn.impute import KNNImputer\n","import pandas as pd\n","\n","\n","\n","# Transpose to treat rows as features (so KNN will work across columns)\n","df_fire_copy_T = df_fire_copy.T\n","\n","# KNN Imputer (now imputes across original columns)\n","knn_imputer = KNNImputer(n_neighbors=3)\n","df_fire_copy_imputed_T = pd.DataFrame(\n","    knn_imputer.fit_transform(df_fire_copy_T),\n","    index=df_fire_copy_T.index,\n","    columns=df_fire_copy_T.columns\n",")\n","# Transpose back to original shape — this was the bug\n","df_fire_copy = df_fire_copy_imputed_T.T\n","\n","# Add back 'underlying' column (assumed to be untouched)\n","df_fire_copy = pd.concat([df_fire['underlying'], df_fire_copy], axis=1)\n","\n","# Fallback mean imputation for any remaining NaNs\n","simp_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n","df_fire_imputed_copy = simp_imp.fit_transform(df_fire_copy)\n","\n","# Convert back to DataFrame\n","df_fire_imputed_copy = pd.DataFrame(df_fire_imputed_copy, columns=df_fire_copy.columns)\n","\n","# Preview\n","df_fire_imputed_copy.head()"],"metadata":{"id":"XnvN8D1YOTFe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_spec_imputed_cols=df_fire_imputed_copy[test_spec_cols]\n","df_test_spec_imputed_cols.head()"],"metadata":{"id":"51ha0LojOsQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_attack=df_fire.drop(test_spec_cols,axis=1)\n","df_attack.head()"],"metadata":{"id":"lfghsqIuO0Ic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire_imputed_copy_trainer=df_fire_imputed_copy.drop(test_spec_cols,axis=1)\n","df_fire_imputed_copy_trainer.head()"],"metadata":{"id":"07VsspKlPANP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: plot of first row  test_iv_cols in df fire, colour predicted values in differnt colour\n","\n","import matplotlib.pyplot as plt\n","# Assuming df_fire and submission_2_3 are already defined and contain the necessary data\n","# Get the first row of df_fire for original values\n","original_first_row = df_fire.iloc[754]\n","\n","# Get the first row of submission_2_3 for predicted values\n","predicted_first_row = df_fire_imputed_copy.iloc[754]\n","\n","# Identify the _iv_ columns from the original dataframe (or test_iv_cols list)\n","iv_cols_to_plot = test_iv_cols # Using the existing list from the preceding code\n","\n","# Extract original and predicted IV values for the first row\n","original_iv_values = original_first_row[iv_cols_to_plot]\n","predicted_iv_values = predicted_first_row[iv_cols_to_plot]\n","\n","# Create the plot\n","plt.figure(figsize=(14, 7))\n","\n","# Plot original values\n","plt.scatter(iv_cols_to_plot, original_iv_values, color='blue', label='Original Values', marker='o')\n","\n","# Plot predicted values in a different color\n","plt.scatter(iv_cols_to_plot, predicted_iv_values, color='red', label='Predicted Values', marker='x')\n","\n","# Add labels and title\n","plt.xlabel('IV Columns')\n","plt.ylabel('IV Value')\n","plt.title('Original vs. Predicted IV Values for the First Sample in Test Data')\n","plt.xticks(rotation=90)\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"wdiOJGEIoJcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_trial=df_attack.copy()"],"metadata":{"id":"AEf3A_Kheyq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iv_cols"],"metadata":{"id":"jLn_dcKp2GFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire_3=df_fire.copy()\n","df_fire_3.head()"],"metadata":{"id":"Eps3Zypq27al"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","knn_reg = KNeighborsRegressor(n_neighbors=5)\n","\n"],"metadata":{"id":"lQw4rJ9OISGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ws69IH_FNifM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for iv in common_call_iv_cols:\n","  X=df_ready.drop([iv] + common_put_iv_cols, axis=1)\n","  y=df_ready[iv]\n","\n","  # Track best model\n","  best_score = -np.inf\n","  best_model = None\n","  best_model_name = None\n","\n","  # Grid search\n","  for name, params in param_grids.items():\n","      pipe = Pipeline([,\n","          (\"regressor\", params[\"regressor\"][0])\n","      ])\n","      grid_search = GridSearchCV(pipe, param_grid=params, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n","      grid_search.fit(X, y)\n","\n","      print(f\"{name} best score: {-grid_search.best_score_:.4f}\")\n","\n","      if grid_search.best_score_ > best_score:\n","          best_score = grid_search.best_score_\n","          best_model = grid_search.best_estimator_\n","          best_model_name = name\n","      best_model.fit(X, y)\n","  print(f\"\\nBest model: {best_model_name} with MSE: {-best_score:.4f}\")\n","\n","  df_fire_imputed_copy_trainer_predictor=df_fire_imputed_copy_trainer.drop([iv] + common_put_iv_cols,axis=1)\n","  for i in range(len(df_attack)):\n","    if np.isnan(df_fire.loc[i, iv]):\n","      df_fire_3.loc[i, iv] = best_model.predict(df_fire_imputed_copy_trainer_predictor.loc[i].values.reshape(1, -1))"],"metadata":{"id":"Ll5GDw2lPO67"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for iv in common_put_iv_cols:\n","  X=df_ready.drop([iv] + common_call_iv_cols, axis=1)\n","  y=df_ready[iv]\n","\n","  # Track best model\n","  best_score = -np.inf\n","  best_model = None\n","  best_model_name = None\n","\n","  # Grid search\n","  for name, params in param_grids.items():\n","      pipe = Pipeline([,\n","          (\"regressor\", params[\"regressor\"][0])\n","      ])\n","      grid_search = GridSearchCV(pipe, param_grid=params, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n","      grid_search.fit(X, y)\n","\n","      print(f\"{name} best score: {-grid_search.best_score_:.4f}\")\n","\n","      if grid_search.best_score_ > best_score:\n","          best_score = grid_search.best_score_\n","          best_model = grid_search.best_estimator_\n","          best_model_name = name\n","  best_model.fit(X, y)\n","  df_fire_imputed_copy_trainer_predictor=df_fire_imputed_copy_trainer.drop([iv] + common_call_iv_cols,axis=1)\n","  for i in range(len(df_attack)):\n","    if np.isnan(df_fire.loc[i, iv]):\n","      df_fire_3.loc[i, iv] = best_model.predict(df_fire_imputed_copy_trainer_predictor.loc[i].values.reshape(1, -1))\n"],"metadata":{"id":"JcDnWUbW-Hhf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","df_fire_3.to_csv('trial.csv',index=False)"],"metadata":{"id":"G93N3eKB9u_I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire_3[test_spec_cols]"],"metadata":{"id":"OHg67eeorTwY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire_3[common_cols].describe().loc['max']"],"metadata":{"id":"qL6loU1RCiw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.impute import KNNImputer\n","import pandas as pd\n","\n","\n","\n","# Transpose to treat rows as features (so KNN will work across columns)\n","df_trial_T = df_trial.T\n","\n","# KNN Imputer (now imputes across original columns)\n","knn_imputer = KNNImputer(n_neighbors=3)\n","df_fire_copy_imputed_T = pd.DataFrame(\n","    knn_imputer.fit_transform(df_fire_copy_T),\n","    index=df_fire_copy_T.index,\n","    columns=df_fire_copy_T.columns\n",")\n","# Transpose back to original shape — this was the bug\n","df_fire_copy = df_fire_copy_imputed_T.T\n","\n","# Add back 'underlying' column (assumed to be untouched)\n","df_fire_copy = pd.concat([df_fire['underlying'], df_fire_copy], axis=1)\n","\n","# Fallback mean imputation for any remaining NaNs\n","simp_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n","df_fire_imputed_copy = simp_imp.fit_transform(df_fire_copy)\n","\n","# Convert back to DataFrame\n","df_fire_imputed_copy = pd.DataFrame(df_fire_imputed_copy, columns=df_fire_copy.columns)\n","\n","# Preview\n","df_fire_imputed_copy.head()"],"metadata":{"id":"jZ_IMK7Hq43x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jdf=pd.read_csv('trial.csv')\n","jdf.head()"],"metadata":{"id":"MOnE24r0dcLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: jdf cells with _iv_ columns should be below test_df[iv_cols].describe().loc['max'].max()\n","\n","#jdf[iv_cols] = jdf[iv_cols].where( (jdf[iv_cols] < test_df[iv_cols].describe().loc['max'].max() ), np.nan)\n","#jdf[iv_cols] = jdf[iv_cols].fillna(method='ffill').fillna(method='bfill')"],"metadata":{"id":"zpu7_0d9Z5is"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jdf[iv_cols].describe().loc['max']"],"metadata":{"id":"wyPO0O3qPSod"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jdf.columns"],"metadata":{"id":"Ydm-9O0cs_ca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_cols"],"metadata":{"id":"sh17O4pPtsKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jdf_call_iv_cols=[col for col in jdf.columns if \"call_iv_\" in col]\n","jdf_call_iv_cols"],"metadata":{"id":"dzoHBKj5ubCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jdf_put_iv_cols=[col for col in jdf.columns if \"put_iv_\" in col]\n","jdf_put_iv_cols"],"metadata":{"id":"2rq0JFdLvqJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_spec_call_iv_cols=[col for col in test_spec_cols if \"call_iv_\" in col]\n","test_spec_call_iv_cols"],"metadata":{"id":"i5eoE8vYu6Lw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_spec_put_iv_cols=[col for col in test_spec_cols if \"put_iv_\" in col]\n","test_spec_put_iv_cols"],"metadata":{"id":"dCSmd81sv3sh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_1=pd.concat([test_df['timestamp'],jdf[jdf_call_iv_cols],df_test_spec_imputed_cols[test_spec_call_iv_cols],jdf[jdf_put_iv_cols],df_test_spec_imputed_cols[test_spec_put_iv_cols]],axis=1)\n","submission_2_1.head()"],"metadata":{"id":"8FpgfKcpuEGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire_2=df_fire.copy()\n","df_fire_2[df_trial.columns]=df_trial[df_trial.columns]\n","df_fire_2.head()"],"metadata":{"id":"4bj7oeRhCJ0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_1.to_csv('submission_2_2.csv',index=False)"],"metadata":{"id":"PzWvCKP9wDQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_1.describe().loc['max']"],"metadata":{"id":"Y0CzUX1myI0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_1[iv_cols].describe().loc['max'].max()"],"metadata":{"id":"-EQJUaF-xpNt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df[iv_cols].describe().loc['max'].max()"],"metadata":{"id":"nQAfgcO-xQgE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for iv in test_spec_call_iv_cols:\n","  X=df_fire_imputed_copy.drop([iv]+test_put_iv_cols, axis=1)\n","  y=df_fire_imputed_copy[iv]\n","\n","  # Track best model\n","  best_score = -np.inf\n","  best_model = None\n","  best_model_name = None\n","\n","  # Grid search\n","  for name, params in param_grids.items():\n","      pipe = Pipeline([,\n","          (\"regressor\", params[\"regressor\"][0])\n","      ])\n","      grid_search = GridSearchCV(pipe, param_grid=params, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n","      grid_search.fit(X, y)\n","\n","      print(f\"{name} best score: {-grid_search.best_score_:.4f}\")\n","\n","      if grid_search.best_score_ > best_score:\n","          best_score = grid_search.best_score_\n","          best_model = grid_search.best_estimator_\n","          best_model_name = name\n","  best_model.fit(X, y)\n","  df_fire_imputed_copy_trainer_predictor_2=df_fire_imputed_copy.drop([iv]+test_put_iv_cols,axis=1)\n","  for i in range(len(df_attack)):\n","    if np.isnan(df_fire_2.loc[i, iv]):\n","      df_fire_3.loc[i, iv] = best_model.predict(df_fire_imputed_copy_trainer_predictor_2.loc[i].values.reshape(1, -1))\n"],"metadata":{"id":"lQOEbC9W--px"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for iv in test_spec_put_iv_cols:\n","  X=df_fire_imputed_copy.drop([iv]+test_call_iv_cols, axis=1)\n","  y=df_fire_imputed_copy[iv]\n","\n","  # Track best model\n","  best_score = -np.inf\n","  best_model = None\n","  best_model_name = None\n","\n","  # Grid search\n","  for name, params in param_grids.items():\n","      pipe = Pipeline([,\n","          (\"regressor\", params[\"regressor\"][0])\n","      ])\n","      grid_search = GridSearchCV(pipe, param_grid=params, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n","      grid_search.fit(X, y)\n","\n","      print(f\"{name} best score: {-grid_search.best_score_:.4f}\")\n","\n","      if grid_search.best_score_ > best_score:\n","          best_score = grid_search.best_score_\n","          best_model = grid_search.best_estimator_\n","          best_model_name = name\n","  best_model.fit(X, y)\n","  df_fire_imputed_copy_trainer_predictor_2=df_fire_imputed_copy.drop([iv]+test_call_iv_cols, axis=1)\n","  for i in range(len(df_attack)):\n","    if np.isnan(df_fire_2.loc[i, iv]):\n","      df_fire_3.loc[i, iv] = best_model.predict(df_fire_imputed_copy_trainer_predictor_2.loc[i].values.reshape(1, -1))\n","\n","df_fire_3.to_csv('trial_2.csv',index=False)"],"metadata":{"id":"4lHaI3HLDVU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire_3.to_csv('trial_2.csv',index=False)"],"metadata":{"id":"BybKQZQC6-Tp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fire_2.head()"],"metadata":{"id":"iDODUXZAD2rP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_3=pd.concat([test_df['timestamp'],df_fire_3[test_iv_cols]],axis=1)\n","submission_2_3.head()"],"metadata":{"id":"B2yyffNUD8-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#submission_2_3[test_iv_cols] = submission_2_3[test_iv_cols].where( (submission_2_3[test_iv_cols] < test_df[test_iv_cols].describe().loc['max'].max() ), np.nan)\n","#submission_2_3[test_iv_cols] = submission_2_3[test_iv_cols].fillna(method='ffill').fillna(method='bfill')"],"metadata":{"id":"yoTH3NeScJB2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_3[test_iv_cols].describe().loc['max'].max()"],"metadata":{"id":"M8ZwJ1alFNvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_3.shape"],"metadata":{"id":"t1FjMlbPEngB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_3.to_csv('submission_2_6.csv',index=False)"],"metadata":{"id":"P6tFLC6vErzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_3.head()"],"metadata":{"id":"KVqudx805qkU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_2_3.isna().sum().sort_values(ascending=False)"],"metadata":{"id":"bzG2sSwe7FM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: #scatter PLOT first sample of OF SUBMISSION 2_3,for the columns having_iv on their name\n","\n","import matplotlib.pyplot as plt\n","# Get the first sample (row) of submission_2_3\n","first_sample = submission_2_3.iloc[0]\n","\n","# Identify columns in the first sample that have \"_iv_\" in their name\n","iv_cols_sample = [col for col in first_sample.index if \"_iv_\" in col]\n","\n","# Extract the values for the identified columns\n","iv_values_sample = first_sample[iv_cols_sample]\n","\n","# Create a scatter plot\n","plt.figure(figsize=(10, 6))\n","plt.scatter(iv_cols_sample, iv_values_sample, marker='o')\n","plt.xticks(rotation=90)\n","plt.ylabel('IV Value')\n","plt.title('Scatter Plot of IV Values for the First Sample in Submission_2_3')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"_nvp11Ylehu5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: #scatter PLOT first sample of OF SUBMISSION 2_3,for the columns having_iv on their name\n","\n","import matplotlib.pyplot as plt\n","# Get the first sample (row) of submission_2_3\n","first_sample = df_fire_imputed_copy.iloc[754]\n","\n","# Identify columns in the first sample that have \"_iv_\" in their name\n","iv_cols_sample = [col for col in first_sample.index if \"_iv_\" in col]\n","\n","# Extract the values for the identified columns\n","iv_values_sample = first_sample[iv_cols_sample]\n","\n","# Create a scatter plot\n","plt.figure(figsize=(10, 6))\n","plt.scatter(iv_cols_sample, iv_values_sample, marker='o')\n","plt.xticks(rotation=90)\n","plt.ylabel('IV Value')\n","plt.title('Scatter Plot of IV Values for the First Sample in Submission_2_3')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"L8ZwfUjJfpsR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: plot of first row  test_iv_cols in df fire, colour predicted values in differnt colour\n","\n","import matplotlib.pyplot as plt\n","# Assuming df_fire and submission_2_3 are already defined and contain the necessary data\n","# Get the first row of df_fire for original values\n","original_first_row = df_fire.iloc[0]\n","\n","# Get the first row of submission_2_3 for predicted values\n","predicted_first_row = submission_2_3.iloc[0]\n","\n","# Identify the _iv_ columns from the original dataframe (or test_iv_cols list)\n","iv_cols_to_plot = test_iv_cols # Using the existing list from the preceding code\n","\n","# Extract original and predicted IV values for the first row\n","original_iv_values = original_first_row[iv_cols_to_plot]\n","predicted_iv_values = predicted_first_row[iv_cols_to_plot]\n","\n","# Create the plot\n","plt.figure(figsize=(14, 7))\n","\n","# Plot original values\n","plt.scatter(iv_cols_to_plot, original_iv_values, color='blue', label='Original Values', marker='o')\n","\n","# Plot predicted values in a different color\n","plt.scatter(iv_cols_to_plot, predicted_iv_values, color='red', label='Predicted Values', marker='x')\n","\n","# Add labels and title\n","plt.xlabel('IV Columns')\n","plt.ylabel('IV Value')\n","plt.title('Original vs. Predicted IV Values for the First Sample in Test Data')\n","plt.xticks(rotation=90)\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"F11E7CQWlt4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["itftj"],"metadata":{"id":"Tac07lamy5y0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_absolute_error_test=[]\n","mean_absolute_error_train=[]\n","y_pred_test_list=[]\n","y_pred_train_list=[]\n","Y_test_list=[]\n","Y_train_list=[]"],"metadata":{"id":"2vONe8J6vV6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for iv in iv_cols:\n","  X=filtered_df.drop(iv, axis=1)\n","  y=filtered_df[iv]\n","  X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=42)\n","  lr.fit(X_train, y_train)\n","  y_pred = lr.predict(X_train)\n","  mean_absolute_error_train.append(mean_absolute_error(y_train, y_pred))\n","  y_pred_test = lr.predict(X_validate)\n","  mean_absolute_error_test.append(mean_absolute_error(y_validate, y_pred_test))\n","  y_pred_test_list.append(y_pred_test)\n","  y_pred_train_list.append(y_pred)\n","  Y_test_list.append(y_validate)\n","  Y_train_list.append(y_train)"],"metadata":{"id":"4W24dtze3kLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot\n","plt.figure(figsize=(10, 6))\n","plt.plot(iv_cols[6:], mean_absolute_error_train[6:], marker='o', label='Train')\n","plt.plot(iv_cols[6:], mean_absolute_error_test[6:], marker='o', label='Test')"],"metadata":{"id":"E8k7WARZ4hRX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_df=pd.DataFrame(Y_test_list)\n","y_train_df=pd.DataFrame(Y_train_list)\n","y_pred_test_df=pd.DataFrame(y_pred_test_list)\n","y_pred_train_df=pd.DataFrame(y_pred_train_list)"],"metadata":{"id":"_lNWGsko_AuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_df.head()"],"metadata":{"id":"KL-dkl6EB-gM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot y_pred_test vs y_test\n","plt.figure(figsize=(10, 6))\n","plt.scatter(y_validate, y_pred_test, label='Test Data')"],"metadata":{"id":"eSXw-Ogu4umq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred"],"metadata":{"id":"Ri0XS_of1tts"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_para=pd.read_parquet('test_data.parquet',engine='auto')"],"metadata":{"id":"D8QRgkkFCXLQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["timestamp_series=df_test_para['timestamp']"],"metadata":{"id":"63AxqfG7x1a7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_para.drop(\"timestamp\",axis=1,inplace=True)"],"metadata":{"id":"iuQ_NZNqriyB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iv_cols_test=[col_test for col_test in df_test_para.columns if \"_iv_\" in col_test]\n","iv_cols_test"],"metadata":{"id":"xOIL1gE3uOPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: show the column names same in test_para and filtered_df\n","\n","test_para_set = df_test_para.columns\n","filtered_df_cols = filtered_df.columns\n","print(\"Columns present in both dataframes:\")\n","common_col_list=[]\n","for common_col in test_para_set.intersection(filtered_df_cols):\n","  common_col_list.append(common_col)"],"metadata":{"id":"1d6VJT4ou_iA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_p1=df_test_para[common_col_list]\n","df_test_p1.shape"],"metadata":{"id":"mGuFjAyPvgis"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_p1"],"metadata":{"id":"I_gokpm0vmOn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_para_copy=df_test_para.copy()"],"metadata":{"id":"xD9OHjnGv83P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer\n","simp_imp=SimpleImputer(missing_values=np.nan, strategy='median')\n","#use imputer\n","imputed_df_test_para_copy=simp_imp.fit_transform(df_test_para_copy)\n","imputed_df_test_para_copy=pd.DataFrame(imputed_df_test_para_copy,columns=df_test_para_copy.columns)\n","imputed_df_test_para_copy.head()"],"metadata":{"id":"gHcPoGNMwR8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_target=imputed_df_test_para_copy[iv_cols_test]\n","df_target.head()"],"metadata":{"id":"tk1fgaeLxK6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#concatenate series_timestamp and  df_target\n","df_target=pd.concat([timestamp_series,df_target],axis=1)\n","df_target.head()"],"metadata":{"id":"qEMSElv-xWrj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_target.to_csv('submission_1_1.csv',index=False)"],"metadata":{"id":"5arHoeGEyI3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uO2wIDs_9COp"},"execution_count":null,"outputs":[]}]}